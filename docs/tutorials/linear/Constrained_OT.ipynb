{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5580f69d",
   "metadata": {},
   "source": [
    "# Constrained Optimal Transport\n",
    "\n",
    "This notebook provides a tutorial on using the {class}`OTT's <ott.solvers.linear.sinkhorn.Sinkhorn>` to solve constrained optimal transport (COT) problems. The tutorial heavily relies on the paper {cite}`tang:24` and the ott-jax package.\n",
    "\n",
    "## Notations\n",
    "\n",
    "Throughout the notebook, we define the following:\n",
    "\n",
    "- **Transport Matrix Set**: Given $a, b \\in \\mathbb{R}^n$, which represent densities, let:\n",
    "  $$\n",
    "  \\mathcal{U}(a, b) = \\left\\{ P \\in \\mathbb{R}_+^{n \\times n} : P\\mathbf{1} = a, \\, P^T\\mathbf{1} = b \\right\\}\n",
    "  $$\n",
    "  denote the set of transport matrices.\n",
    "\n",
    "- **Entry-wise Inner Product**: For $C, P \\in \\mathbb{R}^{n \\times n}$, the entry-wise inner product is defined as:\n",
    "  $$\n",
    "  \\langle C, P \\rangle = \\sum_{1 \\leq i, j \\leq n} C_{ij} P_{ij}\n",
    "  $$\n",
    "\n",
    "- **Entropy Regularization Term**: For $P \\in \\mathbb{R}^{n \\times n}$ and scalars $s_1, \\dots, s_K$, the entropy regularization term is:\n",
    "  $$\n",
    "  H(P, s_1, \\dots, s_K) = \\sum_{1 \\leq i, j \\leq n} P_{ij} \\log P_{ij} + \\sum_{k=1}^K s_k \\log s_k\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02723f8b",
   "metadata": {},
   "source": [
    "## Packages Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eaaedbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from ott.geometry import pointcloud\n",
    "from ott.geometry.geometry import Geometry\n",
    "from ott.problems.linear import linear_problem\n",
    "from ott.solvers.linear import sinkhorn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68909bb7",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9caad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NewtonWrapper:\n",
    "    \"\"\"Wrapper for the Newton solver.\n",
    "    This wrapper is used to provide a consistent interface for the\n",
    "    Newton solver, which is used to solve the linear problem.\n",
    "\n",
    "    Attributes:\n",
    "        obj: The objective function value.\n",
    "        grad: The gradient of the objective function.\n",
    "        hess: The Hessian of the objective function.\n",
    "    \"\"\"\n",
    "\n",
    "    obj: Any\n",
    "    grad: Any\n",
    "    hess: Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6d165",
   "metadata": {},
   "source": [
    "## Constrained Optimal Transport (COT)\n",
    "\n",
    "Given $a, b \\in \\mathbb{R}^n$, a cost matrix $C \\in \\mathbb{R}^{n \\times n}$, and matrices $D_1, \\dots, D_K, D_{K+1}, \\dots, D_{K+L} \\in \\mathbb{R}^{n \\times n}$, the corresponding constrained optimal transport problem (COT) is formulated as:\n",
    "\n",
    "$$\n",
    "\\min_{P \\in \\mathcal{U}(a, b)} \\langle C, P \\rangle \\quad \\text{subject to} \\quad \n",
    "\\begin{array}{cc}\n",
    "\\forall k = 1, \\dots, K & \\langle D_k, P \\rangle \\geq 0 \\\\\n",
    "\\forall l = 1, \\dots, L & \\langle D_{K+l}, P \\rangle = 0\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedLinearProblem:\n",
    "    \"\"\"\n",
    "    This class implements a constrained linear problem with a cost matrix,\n",
    "    constraints, and a regularization parameter epsilon. It provides methods\n",
    "    to round an approximate transport matrix to ensure it lies in the set U(a,b)\n",
    "    and to compute the cost of an approximate transport plan.\n",
    "\n",
    "    Attributes:\n",
    "        a (jnp.array): distribution a of shape (n,)\n",
    "        b (jnp.array): distribution b of shape (n,)\n",
    "        epsilon (float): regularization parameter\n",
    "        cost_matrix (jnp.array): cost matrix of shape (n,n)\n",
    "        constraints (jnp.array): constraints for the transport problem of shape (n,n,K+L)\n",
    "\n",
    "    Methods:\n",
    "        round(F: jnp.array) -> jnp.array:\n",
    "            Round an approximate transport matrix F to ensure it lies in\n",
    "            the set U(a,b)={F: F1=a, F^T1=b, F>=0}.\n",
    "        cost(P: jnp.array) -> jnp.array:\n",
    "            Compute the cost of an approximate transport plan P.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        a: jnp.array,\n",
    "        b: jnp.array,\n",
    "        cost_matrix: jnp.array,\n",
    "        epsilon: float,\n",
    "        constraints: jnp.array = None,\n",
    "    ):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.epsilon = epsilon\n",
    "        self.cost_matrix = cost_matrix\n",
    "        self.constraints = constraints\n",
    "\n",
    "    def round(self, F: jnp.array) -> jnp.array:\n",
    "        \"\"\"Round an approximate transport matrix F to ensure it lies in\n",
    "        the set U(a,b)={F: F1=a, F^T1=b, F>=0}.\n",
    "\n",
    "        Args:\n",
    "            F (jnp.array): approximate transport matrix of shape (n,n)\n",
    "\n",
    "        Returns:\n",
    "            jnp.array: rounded transport matrix lying in U(a,b)\n",
    "        \"\"\"\n",
    "        X = jnp.diag(jnp.minimum(self.a / jnp.sum(F, axis=1), 1))\n",
    "        F = X @ F\n",
    "        Y = jnp.diag(jnp.minimum(self.b / jnp.sum(F, axis=0), 1))\n",
    "        F = F @ Y\n",
    "        err_a, err_b = self.a - jnp.sum(F, axis=1), self.b - jnp.sum(F, axis=0)\n",
    "        return F + jnp.outer(err_a, err_b) / jnp.sum(err_a)\n",
    "\n",
    "    def cost(self, P: jnp.array) -> jnp.array:\n",
    "        \"\"\"Compute the cost of an approximate transport plan P.\n",
    "\n",
    "        Args:\n",
    "            P (jnp.array): approximate transport plan of shape (n,n)\n",
    "\n",
    "        Returns:\n",
    "            jnp.array: cost of the transport plan\n",
    "        \"\"\"\n",
    "        return jnp.sum(self.cost_matrix * round(P, self.a, self.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5e6641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = jnp.array([0.2, 0.5, 0.3])\n",
    "b = jnp.array([0.4, 0.1, 0.5])\n",
    "\n",
    "F = jnp.ones((len(a), len(b)))  # or use random values if you prefer\n",
    "\n",
    "jnp.sum(a).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9f023",
   "metadata": {},
   "source": [
    "## Entropic Relaxation\n",
    "\n",
    "Motivated by the results in {cite}`tang:24`, we solve an entropic relaxation of the COT problem, which has an exponentially close solution to the original COT problem. The entropic relaxation is given by:\n",
    "\n",
    "$$\n",
    "\\min_{P \\in \\mathcal{U}(a, b), \\, s \\in \\mathbb{R}_+^K} \\left( \\langle C, P \\rangle + \\varepsilon H(P, s_1, \\dots, s_K) \\right) \\quad \\text{subject to} \\quad \n",
    "\\begin{array}{cc}\n",
    "\\forall k = 1, \\dots, K & \\langle D_k, P \\rangle = s_k \\\\\n",
    "\\forall l = 1, \\dots, L & \\langle D_{K+l}, P \\rangle = 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "### Primal-Dual Formulation\n",
    "\n",
    "The associated primal-dual problem is given by:\n",
    "\n",
    "$$\n",
    "\\max_{u, v \\in \\mathbb{R}^n; \\, t \\in \\mathbb{R}^{K+L}} \\min_{P, s} L(u, v, t; P, s)\n",
    "$$\n",
    "\n",
    "where the Lagrangian $L(u, v, t; P, s)$ is defined as:\n",
    "\n",
    "$$\n",
    "L(u, v, t; P, s) := \\varepsilon \\langle P, \\log P \\rangle + \\langle C, P \\rangle - \\langle u, P\\mathbf{1} - a \\rangle - \\langle v, P^T\\mathbf{1} - b \\rangle + \\varepsilon \\sum_{k=1}^K s_k \\log s_k + \\sum_{k=1}^K t_k s_k + \\sum_{m=1}^{K+L} h_m \\langle D_m, P \\rangle\n",
    "$$\n",
    "\n",
    "We define the Lyapunov function by $f(u, v, t) = \\min_{P, s} L(u, v, t; P, s)$. By the minimax theorem, solving the entropic relaxation is equivalent to maximizing $f$, which admits the following formulation:\n",
    "\n",
    "$$\n",
    "f(u, v, t) = -\\varepsilon \\sum_{1 \\leq i, j \\leq n} \\exp \\left( \\frac{1}{\\varepsilon} \\left( -C_{ij} + \\sum_{m=1}^{K+L} t_m (D_m)_{ij} + u_i + v_j \\right) - 1 \\right)\n",
    "+ \\sum_{i=1}^n u_i a_i + \\sum_{j=1}^n v_j b_j - \\varepsilon \\sum_{k=1}^K \\exp \\left( - \\frac{1}{\\varepsilon} t_k - 1 \\right)\n",
    "$$\n",
    "\n",
    "with the intermediate transport plan define as: \n",
    "\n",
    "$$ P_\\varepsilon = \\exp \\left( \\frac{1}{\\varepsilon} \\left( -C + \\sum_{m=1}^{K+L} t_m D_m + u\\mathbf{1}^T + \\mathbf{1}v^T \\right) - 1 \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba37228",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstrainedSinkhorn:\n",
    "    \"\"\"\n",
    "    This class implements the constrained Sinkhorn algorithm for solving\n",
    "    the optimal transport problem with constraints. It provides methods\n",
    "    to compute the intermediate transport plan, the Lyapunov function,\n",
    "    and the Newton step for the constrained Sinkhorn problem.\n",
    "\n",
    "    Attributes:\n",
    "        cot_lp (ConstrainedLinearProblem): instance of the constrained linear problem\n",
    "        geometry (Geometry): geometry object for the transport problem\n",
    "        K (int): number of constraints\n",
    "        Ds (jnp.array): constraint matrices of shape (n,n,K+L)\n",
    "\n",
    "    Methods:\n",
    "        intermediate_transport(u: jnp.array, v: jnp.array, h: jnp.array) -> jnp.array:\n",
    "            Compute the intermediate transport plan for the constrained Sinkhorn problem.\n",
    "        lyapunov(u: jnp.array, v: jnp.array, h: jnp.array) -> jnp.array:\n",
    "            Compute the Lyapunov function for the constrained Sinkhorn problem.\n",
    "        newton_step(u: jnp.array, v: jnp.array, convergence_tol: float = 1e-6, max_iter: int = 20):\n",
    "            Compute the Newton step for the constrained Sinkhorn problem.\n",
    "        backtracking_line_search(newton_wrap: NewtonWrapper, t, delta, alpha_start: float = 1.0,\n",
    "            rho: float = 0.5, c: float = 1e-4, max_line_search_iter: int = 20):\n",
    "            Perform backtracking line search to find a suitable step size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cot_lp):\n",
    "        self.cot_lp = cot_lp\n",
    "        self.geometry = Geometry(\n",
    "            cost_matrix=cot_lp.cost_matrix, epsilon=cot_lp.epsilon\n",
    "        )\n",
    "        self.K = cot_lp.constraints[\"K\"]\n",
    "        self.Ds = jnp.copy(cot_lp.constraints[\"matrices\"])  # shape (n, n, K+L)\n",
    "\n",
    "    def intermediate_transport(\n",
    "        self, u: jnp.array, v: jnp.array, h: jnp.array\n",
    "    ) -> jnp.array:\n",
    "        \"\"\"Compute the intermediate transport plan for the constrained Sinkhorn problem.\n",
    "\n",
    "        Args:\n",
    "            u (jnp.array): dual scaling for a of shape (n,)\n",
    "            v (jnp.array): dual scaling for b of shape (n,)\n",
    "            h (jnp.array): constraint dual variables of shape (K+L,)\n",
    "\n",
    "        Returns:\n",
    "            jnp.array: intermediate transport plan of shape (n,n)\n",
    "        \"\"\"\n",
    "        modulation = jnp.tensordot(\n",
    "            self.Ds[:, :, : self.K], h[: self.K], axes=([2], [0])\n",
    "        )\n",
    "        return (\n",
    "            self.geometry.transport_from_potentials(u, v)\n",
    "            * jnp.exp(modulation / self.geometry.epsilon)\n",
    "            / jnp.exp(1)\n",
    "        )\n",
    "\n",
    "    def lyapunov(self, u: jnp.array, v: jnp.array, h: jnp.array) -> jnp.array:\n",
    "        \"\"\"Compute the Lyapunov function for the constrained Sinkhorn problem.\n",
    "\n",
    "        Args:\n",
    "            u (jnp.array): dual scaling for a of shape (n,)\n",
    "            v (jnp.array): dual scaling for b of shape (n,)\n",
    "            h (jnp.array): constraint dual variables of shape (K+L,)\n",
    "\n",
    "        Returns:\n",
    "            jnp.array: Lyapunov function value of shape ()\n",
    "        \"\"\"\n",
    "        # Compute the Lyapunov (objective) function\n",
    "        transp = self.intermediate_transport(u, v, h)\n",
    "        return (\n",
    "            -self.geometry.epsilon * jnp.sum(transp)\n",
    "            + jnp.sum(u * self.cot_lp.a)\n",
    "            + jnp.sum(v * self.cot_lp.b)\n",
    "            - self.geometry.epsilon\n",
    "            * jnp.sum(jnp.exp(-(1 / self.geometry.epsilon) * h[: self.K] - 1))\n",
    "        )\n",
    "\n",
    "    def newton_step(\n",
    "        self,\n",
    "        u: jnp.array,\n",
    "        v: jnp.array,\n",
    "        convergence_tol: float = 1e-6,\n",
    "        max_iter: int = 20,\n",
    "    ):\n",
    "        \"\"\"Compute the Newton step for the constrained Sinkhorn problem.\n",
    "\n",
    "        Args:\n",
    "            u (jnp.array): dual scaling for a of shape (n,)\n",
    "            v (jnp.array): dual scaling for b of shape (n,)\n",
    "            convergence_tol (float): tolerance for convergence\n",
    "            max_iter (int): maximum number of iterations\n",
    "\n",
    "        Returns:\n",
    "            jnp.array: Newton step of shape (K+L,)\n",
    "        \"\"\"\n",
    "\n",
    "        def objective(w: jnp.array) -> jnp.array:\n",
    "            return self.lyapunov(u + w[:1] * jnp.ones_like(u), v, w[1:])\n",
    "\n",
    "        grad_fn = jax.grad(objective)\n",
    "        hess_fn = jax.hessian(objective)\n",
    "\n",
    "        newton_wrap = NewtonWrapper(\n",
    "            obj=objective,\n",
    "            grad=grad_fn,\n",
    "            hess=hess_fn,\n",
    "        )\n",
    "\n",
    "        w = jnp.ones(self.Ds.shape[2] + 1)\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            grad = grad_fn(w)\n",
    "            hess = hess_fn(w)\n",
    "\n",
    "            # Solve Newton direction\n",
    "            delta = -jnp.linalg.solve(hess, grad)\n",
    "\n",
    "            # Line search\n",
    "            alpha = self.backtracking_line_search(newton_wrap, t, delta)\n",
    "\n",
    "            # Update t\n",
    "            t = t + alpha * delta\n",
    "\n",
    "            if jnp.linalg.norm(delta) < convergence_tol:\n",
    "                break\n",
    "\n",
    "        return t\n",
    "\n",
    "    def backtracking_line_search(\n",
    "        self,\n",
    "        newton_wrap: NewtonWrapper,\n",
    "        t,\n",
    "        delta,\n",
    "        alpha_start: float = 1.0,\n",
    "        rho: float = 0.5,\n",
    "        c: float = 1e-4,\n",
    "        max_line_search_iter: int = 20,\n",
    "    ):\n",
    "        \"\"\"Perform backtracking line search to find a suitable step size.\n",
    "\n",
    "        Args:\n",
    "            newton_wrap (NewtonWrapper): wrapper for objective, gradient, and Hessian\n",
    "            t (jnp.array): current point\n",
    "            delta (jnp.array): Newton direction\n",
    "            alpha_start (float): initial step size\n",
    "            rho (float): reduction factor for step size\n",
    "            c (float): sufficient decrease condition constant\n",
    "            max_line_search_iter (int): maximum number of iterations for line search\n",
    "\n",
    "        Returns:\n",
    "            float: step size that satisfies the sufficient decrease condition\n",
    "        \"\"\"\n",
    "        alpha = alpha_start\n",
    "        grad = newton_wrap.grad(t)\n",
    "        slope = jnp.dot(grad, delta)\n",
    "\n",
    "        for _ in range(max_line_search_iter):\n",
    "            if (\n",
    "                newton_wrap.obj(t + alpha * delta)\n",
    "                <= newton_wrap.obj(t) + c * alpha * slope\n",
    "            ):\n",
    "                break\n",
    "            alpha *= rho\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ada9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_with_constraints(\n",
    "    geom, a, b, f_objective, u_init, v_init, t_init, N, eta\n",
    "):\n",
    "    \"\"\"Implements Sinkhorn-type algorithm under linear constraint.\n",
    "\n",
    "    Args:\n",
    "        geom: instance of ConstrainedGeometry\n",
    "        r: left marginal (target row sums)\n",
    "        c: right marginal (target column sums)\n",
    "        f_objective: function that solves the maximization problem in a-step\n",
    "        x_init, y_init: initial dual variables\n",
    "        a_init: initial constraint dual variable\n",
    "        N: number of iterations\n",
    "        eta: regularization parameter (inverse of epsilon)\n",
    "    \"\"\"\n",
    "    u, v, t = u_init, v_init, t_init\n",
    "\n",
    "    for i in range(N):\n",
    "        # Row update\n",
    "        geom.update_dual_t(t)  # Update cost matrix with current a\n",
    "\n",
    "        log_P1 = geom.apply_lse_kernel(u, v) - 1  # log(P @ 1)\n",
    "        u += (jnp.log(a) - log_P1) / eta\n",
    "\n",
    "        log_PT1 = geom.apply_lse_kernel(u, v, axis=1) - 1  # log(P^T @ 1)\n",
    "        v += (jnp.log(b) - log_PT1) / eta\n",
    "\n",
    "        # Constraint dual update (problem-specific)\n",
    "        t_new, h = geom.lyapunov(u, v, t, a, b)\n",
    "        t = t_new\n",
    "\n",
    "        # Update x with shift by t\n",
    "        u += h * jnp.ones_like(u)\n",
    "\n",
    "    return u, v, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bcd34c",
   "metadata": {},
   "source": [
    "## Numerical Experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "constrained_ot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
