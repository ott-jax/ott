{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84682bce",
   "metadata": {},
   "source": [
    "# Sinkhorn for Constrained OT Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c02d8b",
   "metadata": {},
   "source": [
    "In this tutorial, we implement Sinkhorn algorithm for constrained OT problems.\n",
    "Based on the provided algorithm pseudocode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98c6e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from ott.geometry import pointcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68936458",
   "metadata": {},
   "source": [
    "Define r,c,C,n,D,eta globally to access them from any function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d799f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "global r,c,C,n,D,eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "924f815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_constrained_sinkhorn_inputs_consistancy(x_init, y_init, a_init, n_iter):\n",
    "    assert C.shape == (n,n)\n",
    "    assert D.shape == (n,n)\n",
    "    assert r.shape == (n,1)\n",
    "    assert c.shape == (n,1)\n",
    "    assert x_init.shape == (n,1)\n",
    "    assert y_init.shape == (n,1)\n",
    "    assert a_init.shape == (n,1)\n",
    "    assert isinstance(eta,float)\n",
    "    assert n_iter>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988dfc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_P(x, y, a,):\n",
    "    matrix1 = jnp.ones((n,1))\n",
    "    sum_amDm = sum(a[m] * D[m] for m in range(n))\n",
    "    x_dot_M1T = jnp.dot(x,jnp.transpose(matrix1))\n",
    "    M1_dot_yT = jnp.dot(matrix1,jnp.transpose(y))\n",
    "    return jnp.exp(eta * (-C + sum_amDm + x_dot_M1T + M1_dot_yT )- 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f49ab",
   "metadata": {},
   "source": [
    "# Implementation of Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrained_sinkhorn( x_init, y_init, a_init, n_iter=100):\n",
    "  check_constrained_sinkhorn_inputs_consistancy(x_init, y_init, a_init, n_iter)\n",
    "  x, y, a = x_init, y_init, a_init\n",
    "  matrix1 = jnp.ones((n,1))\n",
    "  for _ in range(n_iter):\n",
    "    P = compute_P(x, y, a,)\n",
    "\n",
    "    x = x + (jnp.log(r) - jnp.log(jnp.dot(P, matrix1)))/ eta\n",
    "\n",
    "    P = compute_P(x, y, a,)\n",
    "\n",
    "    y = y + (jnp.log(c) - jnp.log(jnp.dot(jnp.transpose(P), matrix1))) / eta\n",
    "\n",
    "    a, t = optimize(x, y, a,)\n",
    "    x = x + t*matrix1\n",
    "\n",
    "  return x, y, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1705f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x, y, a):\n",
    "    \"\"\"\n",
    "    Compute gradient w.r.t. a and t.\n",
    "    \"\"\"\n",
    "    P = compute_P(x, y, a)\n",
    "\n",
    "    grad_a = jnp.exp(-eta * a - 1) - jnp.dot(jnp.dot(D,P),jnp.ones((n,1)))\n",
    "\n",
    "    grad_x = r - P @ jnp.ones((n, 1))\n",
    "    grad_t = jnp.sum(grad_x)\n",
    "\n",
    "    return jnp.vstack([grad_a, grad_t])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93792119",
   "metadata": {},
   "source": [
    "Implementation of f(x+1t,y,a) using equation (7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b518ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_at(a,t,x,y):\n",
    "    return f(x+t*jnp.ones((n,1)),y,a)\n",
    "\n",
    "def f(x,y,a):\n",
    "    return (-1/eta * sum([jnp.exp(eta * (-C[i,j]\n",
    "                            + sum(a[m] * D[i,j] for m in range(n))\n",
    "                            +x[i]+y[j] ))\n",
    "                            for i in range(n) for j in range(n)])\n",
    "                     + sum(x[i]*r[i] for i in range(n))\n",
    "                     + sum(x[j]*r[j] for j in range(n))\n",
    "                     - 1/eta * (sum(- eta * a[k] -1 for k in range (n))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd188b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian(x, y, a):\n",
    "    P = compute_P(x, y, a)\n",
    "\n",
    "    H = jnp.zeros((n + 1, n + 1))\n",
    "\n",
    "    diag_a = eta ** 2 * jnp.exp(-eta * a - 1).ravel()\n",
    "    H = H.at[:n, :n].set(jnp.diag(diag_a))\n",
    "\n",
    "    diag_P1 = jnp.diag(P @ jnp.ones((n, 1)).ravel())\n",
    "    H_tt = jnp.sum(diag_P1)\n",
    "    return H.at[n, n].set(H_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c70624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_step(x, y, a, t):\n",
    "    \"\"\"\n",
    "    Perform one Newton step on (a, t).\n",
    "    \"\"\"\n",
    "    grad = compute_gradient(x, y, a)\n",
    "    H = compute_hessian(x, y, a)\n",
    "\n",
    "    delta = jnp.linalg.solve(H, -grad)\n",
    "\n",
    "    delta_a = delta[:n]\n",
    "    delta_t = delta[-1]\n",
    "\n",
    "    return delta_a, delta_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d52c5e",
   "metadata": {},
   "source": [
    "Implementation of the standard backtracking line search scheme (Boyd and Vandenberghe, 2004)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b88b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_line_search(f, a, t, delta_a, delta_t, alpha=0.4, beta=0.7):\n",
    "    \"\"\"\n",
    "    Basic backtracking line search.\n",
    "    \"\"\"\n",
    "    s = 1.0\n",
    "    f_current = f(a, t)\n",
    "    grad_norm = jnp.linalg.norm(jnp.vstack([delta_a, delta_t]))\n",
    "    while (f(a + s * delta_a, t + s * delta_t)\n",
    "           < f_current + alpha * s * grad_norm):\n",
    "        s *= beta\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246e2b9",
   "metadata": {},
   "source": [
    "Compute a,t using standard backtracking method and newton_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a47ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x, y, a,  num_steps=10):\n",
    "    \"\"\"\n",
    "    Run Newton optimization over (a, t).\n",
    "    \"\"\"\n",
    "    t = 0\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "        delta_a, delta_t = newton_step(x, y, a, t)\n",
    "        def f(a,t):\n",
    "            return f_at(a,t,x,y)\n",
    "        step_size = backtracking_line_search(f, a, t, delta_a, delta_t)\n",
    "\n",
    "        a = a + step_size * delta_a\n",
    "        t = t + step_size * delta_t\n",
    "\n",
    "    return a, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd23284f",
   "metadata": {},
   "source": [
    "Example of usage in constrained problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d01a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(n=50, seed=0):\n",
    "  rngs = jax.random.split(jax.random.key(seed), 2)\n",
    "  r = jnp.abs(jax.random.normal(rngs[0], (n, 1)))\n",
    "  c = jnp.abs(jax.random.normal(rngs[1], (n, 1)))\n",
    "  return r/jnp.sum(r), c/jnp.sum(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63068464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-05-02 11:48:17,959:jax._src.xla_bridge:909: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "n=50\n",
    "r,c = sample_points(n,seed=1)\n",
    "geom = pointcloud.PointCloud(r,c)\n",
    "C = geom.cost_matrix\n",
    "D = jnp.ones_like(C)\n",
    "eta = 1.\n",
    "x_init = jnp.zeros((n,1))\n",
    "y_init = jnp.zeros((n,1))\n",
    "a_init = jnp.zeros((n,1))\n",
    "\n",
    "x_out, y_out, a_out = constrained_sinkhorn(x_init, y_init, a_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32d7a8b",
   "metadata": {},
   "source": [
    "This implementation seems to work but is really slow as I didn't managed to faithfully reproduce their implementation of the step \n",
    "\n",
    "$a,t\\leftarrow argmax_{\\tilde{a},\\tilde{t}}f(x +\\tilde{t} \\mathbb{1}, y,\\tilde{a})$\n",
    "\n",
    "Hence, my implementation is not in $O(n^2)$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ottenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
